#!/usr/bin/python3
"""
Written by Jinseok Oh, Ph.D.
Estimate adaptation model parameters and store results in a table
This script is based on S3_Summarize_Adaptation_Data.m by Dr. James Finley.
"""
import pickle
import numpy as np
import pandas as pd
from scipy.optimize import curve_fit  # MATLAB's fitnlm equivalent
from scipy.io import loadmat
import argparse

"""
Depending on which data file you provide, we can adapt to it
If data file format is Data_All.mat, generated by running the MATLAB scripts,
then use loadmat and load the data.
If data file format is *.pkl or *.pickle, generated by running the Python
scripts, then use pickle.load to do the job.

I am allowing *.mat input option because you may want to 'reproduce'
what Dr. Finley presents in the videos using his MATLAB scripts.
CMD line will be:
    python3 S3_Summarize_Adaptation_Data.py ./Simulated_Adaptation_Data/xx.mat
where xx is the name of the mat file. If nothing's been changed, then it will
be 'Data_All.mat'

If you are not too worried about everything NOT EQUAL, your CMD line will be:
    python3 S3_Summarize_Adaptation_Data.py ./Simulated_Adaptation_Data/xx.pkl
where xx is the name of the pickle object you defined using
S2_Combine_Adaptation_Data.py.
"""
parser = argparse.ArgumentParser()
parser.add_argument("file", help="Name of the simulated data file", type=str)
args = parser.parse_args()

# Indicator to make some modifications in the for-loop at the bottom
PyUsed = True

# If a mat file is provided, use loadmat to read the file
if args.file.split('.')[1] == 'mat':
    print("You provided a mat file")
    temp = loadmat(args.file)
    Data = temp['Data']
    PyUsed = False
# If a pickle file is provided, follow the Pythonic way
elif args.file.split('.')[1] in ['pkl', 'pickle']:
    print("You provided a pickle object")
    with open(args.file, 'rb') as f:
        Data = pickle.load(f)
    f.close()

# Use nonlinear regression to estimate the coefficienets and rate parameters
# for each participant.
def Double_Exp_Model(x, c0, c1, c2, c3):
    return c0*np.exp(-c1*x) + c2*np.exp(-c3*x)


# Specify initial guess for model parameters
# Vary these values to see if the fitting procedure is sensitive
# to the initial guess.
Coeff_Init = [-0.05, 0.025, -0.05, 0.011]

# Here we can use Pandas DataFrame to store coefficients.
Coefficients_All = pd.DataFrame({'A_Slow': [],
                                 'B_Slow': [],
                                 'A_Fast': [],
                                 'B_Fast': []})

# If using MATLAB's Data_All.mat,
# use this for-loop instead of the one below
for Participant_Num in range(len(Data)):
    if PyUsed:
        cond = Data[Participant_Num]['Good_Data'] == 'y'
        yvals = Data[Participant_Num]['SLA']
        xvals = np.arange(yvals.size)
    else:
        cond = Data[Participant_Num]['Good_Data'] == 'Yes'
        yvals = Data[Participant_Num]['SLA'][0][:, 0]
        xvals = np.arange(yvals.size)
    print(f"Participant Number: {Participant_Num}")
    if cond:
        print("Good Data - proceed to coefficient estimation")
        popt, pcov = curve_fit(Double_Exp_Model,
                               xvals,
                               yvals,
                               p0=Coeff_Init)
        if popt[1] > popt[3]:
            Coefficients_All.loc[Participant_Num] = popt[[2, 3, 0, 1]]
        else:
            Coefficients_All.loc[Participant_Num] = popt
    else:
        print("Bad Data - coefficient estimation not executed")
        Coefficients_All.loc[Participant_Num] = np.full((4), np.nan)

# Save the coefficients to a csv file
Coefficients_All.to_csv('Group_Data.csv', index=False)
